<h1>Interagir avec Google Cloud Storage</h1>
<h2>Aperçu</h2>
<p>Dans cet atelier, vous allez apprendre à créer une machine virtuelle, configurer ses paramètres de sécurité et y accéder à distance.</p>
<h3>Objectifs de l'atelier</h3>
<p>Au cours de cet atelier, vous allez apprendre à réaliser les opérations suivantes :</p>
<ul>
<li>
<p>Créer une instance Compute Engine et définir les paramètres d'accès et de sécurité appropriés</p>
</li>
<li>
<p>Se connecter en SSH à l'instance</p>
</li>
<li>
<p>Installer le package logiciel Git (pour le contrôle des versions du code source)</p>
</li>
<li>
<p>Ingérer des données dans une instance Compute Engine</p>
</li>
<li>
<p>Transformer des données dans l'instance Compute Engine</p>
</li>
<li>
<p>Stocker les données transformées dans Cloud Storage</p>
</li>
<li>
<p>Publier des données Cloud Storage sur le Web</p>
</li>
</ul>
<h2>Présentation</h2>
<p>Dans cet atelier, vous allez démarrer une machine virtuelle, configurer ses paramètres d'accès aux API et vous y connecter à distance.  Les instances Compute Engine s'utilisent généralement à un niveau plus poussé, mais il peut être utile de connaître les principes de base de GCP en cas de problèmes.</p>
<p>Vous effectuerez ensuite manuellement les étapes d'un pipeline de données de type "Ingestion, transformation, publication" :</p>
<ul>
<li>Ingérer des données dans une instance Compute Engine</li>
<li>Transformer des données dans l'instance Compute Engine</li>
<li>Stocker les données transformées dans Cloud Storage</li>
<li>Publier des données Cloud Storage sur le Web</li>
</ul>
<p>Vous utiliserez les données en temps réel sur les séismes publiées par l'Institut d'études géologiques des États-Unis (USGS, United States Geological Survey).</p>
<fragment path="/fragments/startqwiklab"></fragment>
<h2>Tâche 1 : Créer une instance Compute Engine et définir ses paramètres d'accès aux API</h2>
<p>Pour créer une instance Compute Engine, procédez comme suit :</p>
<ol>
<li>
<p>Dans la console GCP, accédez au <strong>menu de navigation</strong> (<img alt="8ab244f9cffa6198.png" src="img/mainmenu.png">), puis cliquez sur <strong>Compute Engine</strong>.</p>
</li>
<li>
<p>Cliquez sur <strong>Create</strong> (Créer) et patientez pendant le chargement du formulaire. Vous allez devoir modifier certaines options sur celui-ci.</p>
</li>
<li>
<p>Dans le champ <strong>Name</strong> (Nom), conservez la valeur par défaut. Dans <strong>Region</strong> (Région), sélectionnez <strong>us-central1</strong>, et dans <strong>Zone</strong> sélectionnez <strong>us-central1-a</strong>.</p>
</li>
<li>
<p>Sous <strong>Identity and API access</strong> (Identité et accès à l'API), dans <strong>Access scopes</strong> (Champs d'application de l'accès), sélectionnez <strong>Allow full access to all Cloud APIs</strong> (Autoriser l'accès complet à l'ensemble des API Cloud) :</p>
<p><img src="img/8ab244f9cffa6198.png" alt="8ab244f9cffa6198.png"></p>
</li>
<li>
<p>Cliquez sur <strong>Create</strong> (Créer).</p>
</li>
</ol>
<h2>Tâche 2 : Se connecter en SSH à l'instance</h2>
<p>Une fois votre instance Compute Engine créée, vous pouvez y accéder à distance à l'aide du protocole Secure Shell (SSH) :</p>
<ol>
<li>
<p>Lorsque l'instance que vous venez de créer est disponible, cliquez sur <strong>SSH</strong> :</p>
<p><img src="img/e4d9f3244db5ba38.png" alt="e4d9f3244db5ba38.png"></p>
<p><strong>Remarque</strong> : Les clés SSH sont transférées automatiquement. Vous pouvez ainsi vous connecter en SSH directement depuis votre navigateur, sans devoir utiliser un autre logiciel.</p>
</li>
<li>
<p>Pour obtenir des informations sur l'instance Compute Engine que vous venez de lancer, saisissez la commande suivante dans votre terminal SSH :</p>
<pre><code class="language-bash">cat /proc/cpuinfo
</code></pre>
</li>
</ol>
<h2>Tâche 3 : Installer le logiciel et ingérer des données USGS</h2>
<ol>
<li>
<p>Dans le terminal SSH, saisissez les commandes suivantes :</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get -y -qq install git
</code></pre>
</li>
<li>
<p>Vérifiez que le logiciel Git est bien installé :</p>
<pre><code class="language-bash">git --version
</code></pre>
</li>
<li>
<p>Sur la ligne de commande, saisissez :</p>
<pre><code class="language-bash">git clone https://github.com/GoogleCloudPlatform/training-data-analyst
</code></pre>
<p>Le code est alors téléchargé depuis GitHub.</p>
<p><strong>Remarque</strong> : Si une erreur d'autorisation git s'affiche, cela signifie vraisemblablement que l'URL GitHub saisie est erronée.  Dans ce cas, copiez et collez le code indiqué ci-dessus.</p>
</li>
<li>
<p>Accédez au dossier correspondant à cet atelier :</p>
<pre><code class="language-bash">cd training-data-analyst/CPB100/lab2b
</code></pre>
</li>
<li>
<p>Examinez le code d'ingestion à l'aide de la commande <strong>less</strong> :</p>
<pre><code class="language-bash">less ingest.sh
</code></pre>
<p>La commande <strong>less</strong> vous permet d'afficher le fichier (appuyez sur la <strong>barre d'espace</strong> pour faire défiler la page vers le bas, sur la touche <strong>B</strong> pour accéder à la page précédente et sur la touche <strong>Q</strong> pour quitter).</p>
<p>Le programme <strong>ingest.sh</strong> télécharge un ensemble de données sur les séismes recueillies par l'Institut d'études géologiques des États-Unis au cours des sept derniers jours.  À quel emplacement ce fichier est-il téléchargé ? Sur le disque ou dans Cloud Storage ?</p>
</li>
<li>
<p>Exécutez le code d'ingestion :</p>
<pre><code class="language-bash">bash ingest.sh
</code></pre>
</li>
<li>
<p>Vérifiez que les données ont été téléchargées :</p>
<pre><code class="language-bash">head earthquakes.csv
</code></pre>
<p>La commande <strong>head</strong> affiche les premières lignes du fichier.</p>
</li>
</ol>
<h2>Tâche 4 : Transformer les données</h2>
<p>Vous allez transformer les données brutes en une carte de l'activité sismique à l'aide d'un programme Python.</p>
<p>Le code de transformation est détaillé dans ce bloc-notes :
<a href="https://github.com/GoogleCloudPlatform/datalab-samples/blob/master/basemap/earthquakes.ipynb">https://github.com/GoogleCloudPlatform/datalab-samples/blob/master/basemap/earthquakes.ipynb</a></p>
<p>N'hésitez pas à le lire en détail pour comprendre le fonctionnement du code de transformation.  Le bloc-notes en lui-même a été écrit dans Datalab, un produit GCP que vous apprendrez à utiliser au cours de cette formation.</p>
<ol>
<li>
<p>Commencez par installer les packages Python nécessaires sur l'instance Compute Engine. Dans votre terminal SSH, saisissez ce qui suit :</p>
<pre><code class="language-bash">bash install_missing.sh
</code></pre>
</li>
<li>
<p>Lorsque vous y êtes invité, saisissez <strong>Y</strong>, puis appuyez sur <strong>Enter</strong>.</p>
</li>
<li>
<p>Exécutez le code de transformation :</p>
<pre><code class="language-bash">python3 transform.py
</code></pre>
</li>
<li>
<p>Si vous affichez le contenu du répertoire, vous remarquerez la présence d'un nouveau fichier image :</p>
<pre><code class="language-bash">ls -l
</code></pre>
</li>
</ol>
<h2>Tâche 5 : Créer un bucket</h2>
<p>Pour créer un bucket dans la console GCP, procédez comme suit :</p>
<ol>
<li>
<p>Dans la console GCP, accédez au <strong>menu de navigation</strong> (<img alt="8ab244f9cffa6198.png" src="img/mainmenu.png">), puis cliquez sur <strong>Storage</strong> (Stockage).</p>
</li>
<li>
<p>Cliquez sur <strong>Create bucket</strong> (Créer un compartiment).</p>
</li>
<li>
<p>Dans le champ <strong>Name</strong> (Nom), saisissez votre <strong>ID du projet</strong>, puis cliquez sur <strong>Create</strong> (Créer). Pour trouver votre <strong>ID de projet</strong>, cliquez sur le projet dans le menu supérieur de la console GCP et copiez la valeur sous <strong>ID</strong> pour le projet sélectionné.</p>
<p>Notez le nom de votre bucket. Pour la suite de cet atelier, remplacez <code>&lt;VOTRE-BUCKET&gt;</code> par le nom de votre bucket.</p>
</li>
</ol>
<h2>Tâche 6 : Stocker des données</h2>
<p>Pour stocker les données d'origine et transformées dans Cloud Storage, procédez comme suit :</p>
<ol>
<li>
<p>Dans votre terminal SSH, saisissez la commande suivante en remplaçant <code>&lt;VOTRE-BUCKET&gt;</code> par le nom du bucket que vous venez de créer :</p>
<pre><code class="language-bash">gsutil cp earthquakes.* gs://&lt;VOTRE-BUCKET&gt;/earthquakes/
</code></pre>
</li>
<li>
<p>Dans la console GCP, cliquez sur le nom du bucket. Trois nouveaux fichiers doivent apparaître dans le dossier contenant les données relatives aux <strong>séismes</strong> (si nécessaire, cliquez sur <strong>Refresh</strong> (Actualiser)).</p>
</li>
</ol>
<h2>Tâche 7 : Publier des fichiers Cloud Storage sur le Web</h2>
<p>Pour publier des fichiers Cloud Storage sur le Web, procédez comme suit :</p>
<pre><code class="language-bash">gsutil acl ch -u AllUsers:R gs://&lt;VOTRE-BUCKET&gt;/earthquakes/*
</code></pre>
<p>Pour le fichier <strong>earthquakes.htm</strong>, cliquez sur <strong>Public link</strong> (Lien public).</p>
<p><img src="img/public_access.png" alt="public_access.png"></p>
<p>Quelle est l'URL du fichier Cloud Storage publié ? A-t-elle un rapport avec le nom de votre bucket et son contenu ?</p>
<p>Citez quelques avantages de la publication dans Cloud Storage :</p>
<fragment path="/fragments/endqwiklab"></fragment>
<h5>Dernière mise à jour du manuel : 08 octobre 2018</h5>
<h5>Dernier test de l'atelier : 08 octobre 2018</h5>
<fragment path="/fragments/copyright"></fragment>
